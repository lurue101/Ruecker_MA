import datetime

import matplotlib as mpl
from matplotlib import pyplot as plt

import numpy as np

from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import ParameterGrid

from prism_kondo.experiment_utils import (
    calc_model_errors,
    run_selector,
    save_experiment_results,
    save_hyperopt_result,
)
from prism_kondo.instance_selection._params_dict import (
    DRIFT_DEPENDENT_PARAMS,
    PARAMS_DICTS_DRIFT,
)
from prism_kondo.model import train_lr_model


class DriftExperimenter:
    def generate_data(self, random_state=None):
        rs = np.random.RandomState(random_state)
        self.X_train = rs.randn(600, 5)
        self.X_test = rs.randn(400, 5)  # 200 validation + 200 test
        base_time = datetime.datetime(2000, 1, 1)
        time_train = np.array(
            [base_time + datetime.timedelta(days=i) for i in range(600)],
            dtype="datetime64[ns]",
        ).astype(np.float32)
        self.X_time = np.hstack([self.X_train, time_train.reshape(-1, 1)])
        self.time_test = np.array(
            [base_time + datetime.timedelta(days=i) for i in range(600, 1000)],
            dtype="datetime64[ns]",
        )

        self.cd_test = np.ones(400)
        # depending on the scenario, the training set is 50/50 old and new concept
        # no drift
        self.cd_none = np.ones(600)
        # sudden drift: in the middle of the train set we switch from the old to the new concept
        self.cd_sudden = np.concatenate([300 * [-1], 300 * [1]])
        # gradual drift: period in the middle with both old and new concept interleaved
        self.cd_gradual = np.concatenate(
            [200 * [-1], np.random.choice([-1, 1], 200, True), 200 * [1]]
        )
        # incremental drift: period in the middle with a slow shift to the new concept
        self.cd_increment = np.concatenate(
            [200 * [-1], np.linspace(-1, 1, 200), 200 * [1]]
        )
        # reoccurring concept: interleaved periods with old and new concept (e.g., seasonal patterns)
        self.cd_reoccurring = np.concatenate(
            [100 * [-1], 100 * [1], 100 * [-1], 100 * [1], 100 * [-1], 100 * [1]]
        )

        # noise added to the target
        eps_train = 0.1 * np.random.randn(600)
        eps_test = 0.1 * np.random.randn(400)
        # true coefficients -> coef for 1st variable: old concept -2, new concept 2
        w = np.array([2, 4, -3, 1, -1])

        # compute y with given concept drift scenario (in 1st variable)
        def compute_y(X, cd, eps):
            return (
                w[0] * cd * X[:, 0]
                + w[1] * X[:, 1]
                + w[2] * X[:, 2]
                + w[3] * X[:, 3]
                + w[4] * X[:, 4]
                + eps
            )

        self.y_test = compute_y(self.X_test, self.cd_test, eps_test)
        self.y_none = compute_y(self.X_train, self.cd_none, eps_train)
        self.y_sudden = compute_y(self.X_train, self.cd_sudden, eps_train)
        self.y_gradual = compute_y(self.X_train, self.cd_gradual, eps_train)
        self.y_increment = compute_y(self.X_train, self.cd_increment, eps_train)
        self.y_reoccurring = compute_y(self.X_train, self.cd_reoccurring, eps_train)

    def train_and_eval(self, y_train, drift_scores):
        """
        Inputs:
            y_train
                array with training y (with or without drift)
            drift_scores
                array with scores between 1 and -1 indicating new or old concept,
                generated by the drift detection method

        Returns:
            scores
                R^2 scores on the test set when training the model with the first
                50, 100, 150, ..., 600 training samples ranked according to the drift scores
        """
        # reverse arg sort -> indices of best to worst samples
        idx = np.argsort(drift_scores)[::-1]
        scores = []
        for n in range(50, 601, 50):
            # train model on best n samples
            model = LinearRegression().fit(self.X_train[idx[:n]], y_train[idx[:n]])
            # compute R^2 on test set, i.e., last 200 points
            scores.append(model.score(self.X_test[200:], self.y_test[200:]))
        return scores

    def run_experiments(self, selectors, drift_type, flip_data=False, n=10):
        for i in range(n):
            if (i + 1) % 5 == 0:
                print(i + 1, "/", n)
            self.generate_data()
            y_train, cd = self.y_from_drift_type(drift_type)
            if flip_data is True:
                self.X_train, y_train, cd = (
                    np.flip(self.X_train),
                    np.flip(y_train),
                    np.flip(cd),
                )
                results_dir = "results_drift_flipped"
            else:
                results_dir = "results_drift"
            for selector in selectors:
                if selector in ["fixed_window", "reg_enn_time"]:
                    labels, scores = run_selector(
                        self.X_time, y_train, selector, PARAMS_DICTS_DRIFT[selector]
                    )
                elif selector == "ground_truth":
                    labels = np.zeros(self.X_train.shape[0], dtype="bool")
                    scores = cd
                    ground_truth_labels = np.argwhere(cd == 1)
                    labels[ground_truth_labels] = True
                elif selector in ["drop_three_rt"]:
                    labels, scores = run_selector(
                        self.X_train,
                        y_train,
                        selector,
                        DRIFT_DEPENDENT_PARAMS[drift_type][selector],
                    )
                elif selector in ["fish1"]:
                    x_target = np.hstack(
                        [self.X_test[0, :], self.time_test[0].astype(np.float32)]
                    )
                    X_fish = np.vstack([self.X_time, x_target])
                    labels, scores = run_selector(
                        X_fish,
                        y_train,
                        selector,
                        DRIFT_DEPENDENT_PARAMS[drift_type][selector],
                    )
                else:
                    labels, scores = run_selector(
                        self.X_train, y_train, selector, PARAMS_DICTS_DRIFT[selector]
                    )
                model = train_lr_model(self.X_train[labels, :], y_train[labels])
                error_dict = calc_model_errors(
                    model, self.X_test[200:, :], self.y_test[200:]
                )
                if selector in ["drop_three_rt", "fish1"]:
                    params_dict = DRIFT_DEPENDENT_PARAMS[drift_type][selector]
                else:
                    params_dict = PARAMS_DICTS_DRIFT[selector]
                save_experiment_results(
                    selector,
                    drift_type,
                    labels,
                    scores,
                    error_dict,
                    f"{str(datetime.datetime.today())}",
                    "",
                    params_dict,
                    results_dir,
                )

    def run_hyperopt(
        self, selector_name, param_dict_ranges, drift_type, output_dir="hyperopt_drift"
    ):
        self.generate_data()
        y_train, _ = self.y_from_drift_type(drift_type)
        all_param_combinations = list(ParameterGrid(param_dict_ranges))
        for param_dict in all_param_combinations:
            if selector_name == "reg_enn_time":
                boolean_labels, scores = run_selector(
                    self.X_time, y_train, selector_name, param_dict
                )
            elif selector_name == "fish1":
                x_target = np.hstack(
                    [self.X_test[0, :], self.time_test[0].astype(np.float32)]
                )
                X_fish = np.vstack([self.X_time, x_target])
                boolean_labels, scores = run_selector(
                    X_fish, y_train, selector_name, param_dict
                )
            else:
                boolean_labels, scores = run_selector(
                    self.X_train, y_train, selector_name, param_dict
                )
            model = train_lr_model(
                self.X_train[boolean_labels, :], y_train[boolean_labels]
            )
            error_dict = calc_model_errors(
                model, self.X_test[:200, :], self.y_test[:200]
            )
            save_hyperopt_result(
                selector_name, param_dict, error_dict, drift_type, "", output_dir
            )

    def y_from_drift_type(self, drift_type):
        if drift_type == "none":
            return self.y_none, self.cd_none
        if drift_type == "sudden":
            return self.y_sudden, self.cd_sudden
        elif drift_type == "gradual":
            return self.y_gradual, self.cd_gradual
        elif drift_type == "increment":
            return self.y_increment, self.cd_increment
        elif drift_type == "reoccurring":
            return self.y_reoccurring, self.cd_reoccurring
        else:
            raise ValueError(f"drift type {drift_type} doesnt exist")

    def fill_scores(self, y_train, cd, scores_dict, drift_type):
        for selector in scores_dict.keys():
            if selector == "recent":
                recent_scores = self.train_and_eval(
                    y_train, np.linspace(-1, 1, len(y_train))
                )
                scores_dict["recent"] = scores_dict["recent"] + recent_scores
            elif selector == "ground_truth":
                ground_truth_scores = self.train_and_eval(y_train, cd)
                scores_dict["ground_truth"] = (
                    scores_dict["ground_truth"] + ground_truth_scores
                )
            elif selector == "reg_enn_time":
                labels, scores = run_selector(
                    self.X_time, y_train, selector, PARAMS_DICTS_DRIFT[selector]
                )
                scores = self.train_and_eval(y_train, scores)
                scores_dict[selector] = scores_dict[selector] + scores
            elif selector == "fish1":
                x_target = np.hstack(
                    [self.X_test[0, :], self.time_test[0].astype(np.float32)]
                )
                X_fish = np.vstack([self.X_time, x_target])
                labels, scores = run_selector(
                    X_fish,
                    y_train,
                    selector,
                    DRIFT_DEPENDENT_PARAMS[drift_type][selector],
                )
                scores = self.train_and_eval(y_train, scores)
                scores_dict[selector] = scores_dict[selector] + scores
            elif selector == "selcon":
                X_train_and_val = np.vstack([self.X_train, self.X_test[:200, :]])
                y_train_and_val = np.concatenate([y_train, self.y_test[:200]])
                labels, scores = run_selector(
                    X_train_and_val,
                    y_train_and_val,
                    selector,
                    PARAMS_DICTS_DRIFT[selector],
                )
                scores = self.train_and_eval(y_train, scores[:600])
                scores_dict[selector] = scores_dict[selector] + scores
            elif selector == "drop_three_rt":
                abels, scores = run_selector(
                    self.X_train,
                    y_train,
                    selector,
                    DRIFT_DEPENDENT_PARAMS[drift_type][selector],
                )
                scores = self.train_and_eval(y_train, scores)
                scores_dict[selector] = scores_dict[selector] + scores
            else:
                labels, scores = run_selector(
                    self.X_train, y_train, selector, PARAMS_DICTS_DRIFT[selector]
                )
                scores = self.train_and_eval(y_train, scores)
                scores_dict[selector] = scores_dict[selector] + scores
        return scores_dict

    def calc_mean_scores_dict(self, selectors, drift_type, n=10):
        scores_dict = {selector: np.zeros(12) for selector in selectors}
        for i in range(n):
            self.generate_data()
            y, cd = self.y_from_drift_type(drift_type)
            scores_dict = self.fill_scores(y, cd, scores_dict, drift_type)
        for k in scores_dict.keys():
            scores_dict[k] = scores_dict[k] / n
        return scores_dict

    def generate_random_lines(self, drift_type, n):
        y, _ = self.y_from_drift_type(drift_type)
        random_scores = []
        for i in range(n):
            # pseudo drift scores
            drift_scores = np.random.uniform(-1, 1, 600)
            random_scores.append(self.train_and_eval(y, drift_scores))
        return random_scores

    def create_pca_plot(self):
        self.generate_data()
        pca = PCA(2)
        X = pca.fit_transform(self.X_train)
        X_test = pca.transform(self.X_test)
        fig, axes = plt.subplots(1, 2, figsize=(15, 10), sharey=True)
        axes[0].scatter(X[:, 0], X[:, 1], c=self.y_none, cmap="seismic")
        axes[0].set_title("a)     Clean Data Set")
        size = np.ones(400) * 20
        axes[1].scatter(X_test[:, 0], X_test[:, 1], c=self.y_test, cmap="seismic")
        axes[1].set_title(f"b)     Noisy Data Set % )")

        fig.supxlabel("Principal Component 1", fontsize=16, y=0.06)
        fig.supylabel("Principal Component 2", fontsize=16, x=0.08)
        cmap = mpl.cm.get_cmap("seismic")
        norm = mpl.colors.Normalize(vmin=self.y_sudden.min(), vmax=self.y_sudden.max())
        cbar = plt.colorbar(
            mpl.cm.ScalarMappable(norm=norm, cmap=cmap),
            ax=axes[1],
        )
        cbar.set_label(label="y Value", size="large", weight="bold")
